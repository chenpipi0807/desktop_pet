"""
AIåŠ¨ç”»åˆ¶ä½œå·¥å…· v3.0 - æ‰¹é‡å¤„ç†ç‰ˆ
æ”¯æŒæ‰¹é‡å°†å¤šä¸ªè§†é¢‘è½¬æ¢ä¸ºé€æ˜èƒŒæ™¯GIFåŠ¨ç”»
"""

import cv2
import numpy as np
from PIL import Image, ImageTk, ImageSequence
import os
from rembg import remove
import glob

class VideoProcessor:
    def __init__(self, source_dir="image", output_dir="image"):
        self.source_dir = source_dir
        self.output_dir = output_dir
        
        # åŠ¨ç”»ç±»åˆ«é…ç½®
        self.animation_config = {
            "basic": ["åŸºç¡€01", "åŸºç¡€02", "åŸºç¡€03", "åŸºç¡€04", "åŸºç¡€05"],
            "emotions": {
                "sad": "ä¼¤å¿ƒ",
                "surprised": "åƒæƒŠ", 
                "shy": "å®³ç¾",
                "angry": "æ„¤æ€’",
                "praise": "ç§°èµ",
                "contempt": "é„™è§†"
            }
        }
        
        print("ğŸ¼ AIåŠ¨ç”»åˆ¶ä½œå·¥å…· v3.0 - æ‰¹é‡å¤„ç†ç‰ˆ")
        print("=" * 60)
        self.check_dependencies()
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–åŒ…"""
        try:
            import cv2
            import numpy as np
            from PIL import Image
            from rembg import remove
            print("âœ… æ‰€æœ‰ä¾èµ–åŒ…æ£€æŸ¥é€šè¿‡")
        except ImportError as e:
            print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
            exit(1)
    
    def get_video_files(self):
        """è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„è§†é¢‘æ–‡ä»¶"""
        video_files = []
        pattern = os.path.join(self.source_dir, "*.mp4")
        
        for file_path in glob.glob(pattern):
            filename = os.path.basename(file_path)
            name_without_ext = os.path.splitext(filename)[0]
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨å¯¹åº”çš„GIF
            gif_path = os.path.join(self.output_dir, f"{name_without_ext}.gif")
            if not os.path.exists(gif_path):
                video_files.append((file_path, name_without_ext))
            else:
                print(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨çš„GIF: {name_without_ext}.gif")
        
        return video_files
    
    def extract_frames(self, video_path, max_frames=None):
        """æå–è§†é¢‘å¸§"""
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            raise Exception(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        print(f"è§†é¢‘ä¿¡æ¯: {total_frames} å¸§, {fps:.2f} FPS")
        
        # è®¡ç®—æŠ½å¸§é—´éš”
        if max_frames is None or total_frames <= max_frames:
            frame_step = 1
            target_frames = total_frames
            print(f"ğŸ“½ï¸ å°†æå–å…¨éƒ¨ {total_frames} å¸§")
        else:
            frame_step = total_frames // max_frames
            target_frames = max_frames
            print(f"ğŸ“½ï¸ å°†ä» {total_frames} å¸§ä¸­æŠ½å– {target_frames} å¸§ (æ¯ {frame_step} å¸§æŠ½ä¸€å¸§)")
        
        frames = []
        frame_count = 0
        
        while cap.isOpened() and len(frames) < target_frames:
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_count % frame_step == 0:
                frames.append(frame)
            
            frame_count += 1
        
        cap.release()
        print(f"âœ… æå–äº† {len(frames)} å¸§")
        return frames
    
    def remove_watermark(self, frame):
        """ç§»é™¤å³ä¸‹è§’æ°´å°"""
        height, width = frame.shape[:2]
        
        # å®šä¹‰æ°´å°åŒºåŸŸ (å³ä¸‹è§’)
        watermark_region = frame[int(height*0.8):height, int(width*0.7):width]
        
        # åˆ›å»ºæ©ç 
        mask = np.zeros(watermark_region.shape[:2], dtype=np.uint8)
        mask.fill(255)
        
        # ä½¿ç”¨inpaintç§»é™¤æ°´å°
        result_region = cv2.inpaint(watermark_region, mask, 3, cv2.INPAINT_TELEA)
        
        # å°†ç»“æœæ”¾å›åŸå›¾
        result_frame = frame.copy()
        result_frame[int(height*0.8):height, int(width*0.7):width] = result_region
        
        return result_frame
    
    def remove_background(self, frame):
        """ç§»é™¤èƒŒæ™¯ï¼Œä¿æŒé€æ˜"""
        # è½¬æ¢ä¸ºPILæ ¼å¼
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(frame_rgb)
        
        # ç§»é™¤èƒŒæ™¯
        result = remove(pil_image)
        
        return result
    
    def process_single_video(self, video_path, output_name):
        """å¤„ç†å•ä¸ªè§†é¢‘"""
        print(f"\nğŸ¬ å¤„ç†è§†é¢‘: {output_name}")
        print("-" * 40)
        
        try:
            # æå–å¸§
            print("ğŸ“¹ æ­£åœ¨æå–è§†é¢‘å¸§...")
            frames = self.extract_frames(video_path)
            
            processed_frames = []
            total_frames = len(frames)
            
            for i, frame in enumerate(frames):
                print(f"ğŸ“¸ å¤„ç†ç¬¬ {i+1}/{total_frames} å¸§...")
                
                # ç§»é™¤æ°´å°
                print("ğŸ§¹ æ­£åœ¨ç§»é™¤æ°´å°...")
                frame_no_watermark = self.remove_watermark(frame)
                
                # ç§»é™¤èƒŒæ™¯
                print("ğŸ¨ æ­£åœ¨ç§»é™¤èƒŒæ™¯...")
                transparent_frame = self.remove_background(frame_no_watermark)
                
                # è°ƒæ•´å¤§å°
                resized_frame = transparent_frame.resize((150, 150), Image.Resampling.LANCZOS)
                processed_frames.append(resized_frame)
            
            # åˆ›å»ºGIF
            print("ğŸ¬ æ­£åœ¨åˆ›å»ºGIFåŠ¨ç”»...")
            output_path = os.path.join(self.output_dir, f"{output_name}.gif")
            
            processed_frames[0].save(
                output_path,
                save_all=True,
                append_images=processed_frames[1:],
                duration=42,  # 24fps (1000ms Ã· 24 â‰ˆ 42ms) - ä¿æŒ5ç§’æ’­æ”¾æ—¶é—´
                loop=0,
                transparency=0,
                disposal=2
            )
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(output_path) / 1024  # KB
            
            print(f"âœ… GIFåŠ¨ç”»å·²ä¿å­˜: {output_name}.gif")
            print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.1f} KB")
            print(f"ğŸ–¼ï¸ å¸§æ•°: {len(processed_frames)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
            return False
    
    def process_all_videos(self):
        """æ‰¹é‡å¤„ç†æ‰€æœ‰è§†é¢‘"""
        video_files = self.get_video_files()
        
        if not video_files:
            print("ğŸ‰ æ‰€æœ‰è§†é¢‘éƒ½å·²è½¬æ¢å®Œæˆï¼")
            return
        
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶...")
        print("=" * 60)
        
        success_count = 0
        total_count = len(video_files)
        
        for video_path, output_name in video_files:
            if self.process_single_video(video_path, output_name):
                success_count += 1
        
        print("\n" + "=" * 60)
        print(f"ğŸŠ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š æˆåŠŸ: {success_count}/{total_count}")
        
        if success_count == total_count:
            print("ğŸ‰ æ‰€æœ‰è§†é¢‘è½¬æ¢æˆåŠŸï¼")
            self.show_animation_summary()
        else:
            print(f"âš ï¸ {total_count - success_count} ä¸ªè§†é¢‘å¤„ç†å¤±è´¥")
    
    def show_animation_summary(self):
        """æ˜¾ç¤ºåŠ¨ç”»åº“æ€»ç»“"""
        print("\nğŸ­ åŠ¨ç”»åº“æ€»ç»“:")
        print("-" * 40)
        
        # åŸºç¡€åŠ¨ç”»
        print("ğŸ“‚ åŸºç¡€åŠ¨ç”» (éšæœºæ’­æ”¾):")
        for basic_name in self.animation_config["basic"]:
            gif_path = os.path.join(self.output_dir, f"{basic_name}.gif")
            if os.path.exists(gif_path):
                print(f"  âœ… {basic_name}.gif")
            else:
                print(f"  âŒ {basic_name}.gif (ç¼ºå¤±)")
        
        # æƒ…ç»ªåŠ¨ç”»
        print("\nğŸ˜Š æƒ…ç»ªåŠ¨ç”» (AIè§¦å‘):")
        for emotion_key, emotion_name in self.animation_config["emotions"].items():
            gif_path = os.path.join(self.output_dir, f"{emotion_name}.gif")
            if os.path.exists(gif_path):
                print(f"  âœ… {emotion_name}.gif ({emotion_key})")
            else:
                print(f"  âŒ {emotion_name}.gif ({emotion_key}) (ç¼ºå¤±)")
        
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥: è¿è¡Œ voice_pet.py æŸ¥çœ‹å¤šåŠ¨ç”»æ•ˆæœï¼")

# ä¸»ç¨‹åº
if __name__ == "__main__":
    try:
        processor = VideoProcessor()
        processor.process_all_videos()
        
        print("\næŒ‰å›è½¦é”®é€€å‡º...")
        input()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {str(e)}")
        print("\næŒ‰å›è½¦é”®é€€å‡º...")
        input()
